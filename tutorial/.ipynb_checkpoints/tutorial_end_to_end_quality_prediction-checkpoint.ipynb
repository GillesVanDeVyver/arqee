{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed720652-abca-4195-9b61-769d73a96497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T02:36:20.225401Z",
     "start_time": "2024-09-24T02:36:16.173542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install the package from bitbucket.\n",
    "!pip uninstall arqee -y # remove existing installation, if any\n",
    "!pip install ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281a9c4-6eef-425b-b6cf-b0a09be11368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T02:36:43.955229Z",
     "start_time": "2024-09-24T02:36:20.263951Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some additional libraries for the toturial\n",
    "!pip install matplotlib\n",
    "!pip install gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a1b58-485c-4214-afd8-b53ea95f8fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:26:28.917752Z",
     "start_time": "2024-06-17T09:26:28.132671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Donwload a small sample of test data\n",
    "# This will download +-240Mb of data under ./local__data/sample_data\n",
    "import os\n",
    "import arqee\n",
    "current_directory = os.getcwd()\n",
    "download_loc = os.path.join(current_directory,\"local_data\")\n",
    "arqee.download_data_sample(download_loc,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43298e9-bf29-4bf1-a58b-5db78eae4b8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:26:36.688923Z",
     "start_time": "2024-06-17T09:26:36.534480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load a sample\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sample_alax = np.load(os.path.join(download_loc,\"sample_data/alax.npy\"))\n",
    "# sample_alax is an ndarray of shape (nb_frames,height,width) with values in range [0,255]\n",
    "sample_frame = sample_alax[-1]\n",
    "plt.imshow(sample_frame, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3e033-265f-4e11-8648-9dcd91ee7067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:26:37.395737Z",
     "start_time": "2024-06-17T09:26:37.392359Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Download the end-to-end quality model.\n",
    "Remarks:\n",
    "    - The model is trained and tested on apical 4 chamber (A4C), apiacal 2 chamber (A2C) and apiacal long axis (ALAX) views.\n",
    "'''\n",
    "model_name = 'mobilenetv2_regional_quality'\n",
    "arqee.download_and_set_up_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4e02b-9b0c-4ef6-b42e-6d20fe8f8415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:26:44.866020Z",
     "start_time": "2024-06-17T09:26:44.821900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Once the model is set up in arqee, you can load it as follows:\n",
    "model_object = arqee.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e3e94-72df-4e2b-9b0f-da20b44a45f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:26:45.673959Z",
     "start_time": "2024-06-17T09:26:45.630382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run quality inference on a single frame\n",
    "# model_object.predict_img expects the data to be in the format (nb_channels,height,width)\n",
    "sample_frame_with_channel = np.expand_dims(sample_frame, axis=0) # add channel dimension\n",
    "print(sample_frame_with_channel)\n",
    "res_labels = model_object.predict_img(sample_frame_with_channel,verbose=True)\n",
    "print(res_labels)\n",
    "# This gives quality scores in a continuous scale matched fitted on the annotations of the clinicians, with meaning:\n",
    "# 0: not visible, 1 poor, 3 ok, 4 good, 5 excellent\n",
    "# If you want the labels in categorical format, set convert_to_labels to True\n",
    "res_labels_cat = model_object.predict_img(sample_frame_with_channel,convert_to_labels=True,verbose=False)\n",
    "# The output of the inference is a ndarray with size 1x8 with the quality labels in the following order:\n",
    "# basal_left,mid_left,apical_left,apical_right,mid_right,basal_right,annulus_left,annulus_right\n",
    "print(res_labels_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0f57a-3c94-452e-9b33-46ed5240cac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:10:49.165414Z",
     "start_time": "2024-06-07T14:10:47.630896Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can also run inference on a recording\n",
    "# model_object.predict_recording expects the data to be in the format (nb_frames,nb_channels,height,width)\n",
    "sample_alax_with_channel = np.expand_dims(sample_alax, axis=1) # add channel dimension\n",
    "res_labels_rec = model_object.predict_recording(sample_alax_with_channel,convert_to_labels=True,verbose=True)\n",
    "# The output of the inference is a ndarray with size nb_framesx8 with the quality labels in the following order:\n",
    "# basal_left,mid_left,apical_left,apical_right,mid_right,basal_right,annulus_left,annulus_right\n",
    "print(res_labels_rec)\n",
    "print(res_labels_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65878a-0d6d-4012-b55b-23fe97528ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:10:49.174427Z",
     "start_time": "2024-06-07T14:10:49.172388Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Let's visualize the results\n",
    "For this, we first need a segmentation model to get the regions of interest the model is referring to when making predictions. To download the model, we use the same procedure as the quality model.\n",
    "There are two segmentation models available:\n",
    "    - 'nnunet_hunt4_alax' (33M parameters)\n",
    "    - 'nnunet_hunt4_a2c_a4c'  (33M parameters)\n",
    "Remarks:\n",
    "    - The models are trained on the NTNU internal HUNT4 dataset. \n",
    "'''\n",
    "model_name_seg = 'nnunet_hunt4_alax'\n",
    "arqee.download_and_set_up_model(model_name_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a27f05f17a1216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:10:50.169389Z",
     "start_time": "2024-06-07T14:10:49.174986Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Once the model is set up in arqee, we can load it as follows:\n",
    "model_object_seg = arqee.load_model(model_name_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf90a02ffcb73a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:10:50.303910Z",
     "start_time": "2024-06-07T14:10:50.170353Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we can run the segmentation\n",
    "segmentation_sample = model_object_seg.predict_img(sample_frame_with_channel,verbose=False)\n",
    "plt.imshow(segmentation_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df6179d1650720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:10:50.348445Z",
     "start_time": "2024-06-07T14:10:50.304730Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# With the segmentation available, we can visualize the quality predictions\n",
    "from skimage.transform import resize\n",
    "\n",
    "sample_frame_resized = resize(sample_frame, (256, 256), preserve_range=True)\n",
    "_ = arqee.plot_quality_prediction_result(sample_frame_resized,segmentation_sample,res_labels_cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e4b3cbd41a8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:10:50.349301Z",
     "start_time": "2024-06-07T14:10:50.349218Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's visualize the results for a recording\n",
    "from tqdm import tqdm\n",
    "import gif\n",
    "print('Running inference on the recording')\n",
    "res_segmentations = model_object_seg.predict_recording(sample_alax_with_channel, verbose=True)\n",
    "\n",
    "@gif.frame\n",
    "def plot_frame(sample_frame,sample_seg,quality_labels):\n",
    "    resized_frame = resize(sample_frame[0], (256, 256), preserve_range=True)\n",
    "    arqee.plot_quality_prediction_result(resized_frame, sample_seg,quality_labels)\n",
    "\n",
    "print('Creating gif')\n",
    "frames = [plot_frame(sample_alax_with_channel[i], res_segmentations[i],res_labels_rec[i]) for i in tqdm(range(len(sample_alax_with_channel)))]\n",
    "gif.save(frames, \"image_quality_prediction.gif\", duration=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de119c623a0cbcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "with open('./image_quality_prediction.gif','rb') as f:\n",
    "    display(Image(data=f.read(), format='png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arqee_public2",
   "language": "python",
   "name": "arqee_public"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
